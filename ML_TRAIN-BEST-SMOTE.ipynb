{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sqlalchemy import create_engine\n",
    "from keys import sqlkey\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATABASE CONNECTION\n",
    "engine = create_engine('postgresql://postgres:'+sqlkey+'@localhost:5432/horse_races')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_sql(sql='select * from best_ranked_data',con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>won</th>\n",
       "      <th>distance</th>\n",
       "      <th>race_class</th>\n",
       "      <th>sec_time1</th>\n",
       "      <th>sec_time2</th>\n",
       "      <th>sec_time3</th>\n",
       "      <th>sec_time4</th>\n",
       "      <th>ldr_time1</th>\n",
       "      <th>...</th>\n",
       "      <th>behind_sec1</th>\n",
       "      <th>behind_sec2</th>\n",
       "      <th>behind_sec3</th>\n",
       "      <th>behind_sec4</th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>place_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [race_id, horse_id, won, distance, race_class, sec_time1, sec_time2, sec_time3, sec_time4, ldr_time1, ldr_time2, ldr_time3, ldr_time4, lengths_behind, behind_sec1, behind_sec2, behind_sec3, behind_sec4, time1, time2, time3, time4, win_odds, place_odds]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>won</th>\n",
       "      <th>distance</th>\n",
       "      <th>race_class</th>\n",
       "      <th>sec_time1</th>\n",
       "      <th>sec_time2</th>\n",
       "      <th>sec_time3</th>\n",
       "      <th>sec_time4</th>\n",
       "      <th>ldr_time1</th>\n",
       "      <th>...</th>\n",
       "      <th>behind_sec1</th>\n",
       "      <th>behind_sec2</th>\n",
       "      <th>behind_sec3</th>\n",
       "      <th>behind_sec4</th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>place_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [race_id, horse_id, won, distance, race_class, sec_time1, sec_time2, sec_time3, sec_time4, ldr_time1, ldr_time2, ldr_time3, ldr_time4, lengths_behind, behind_sec1, behind_sec2, behind_sec3, behind_sec4, time1, time2, time3, time4, win_odds, place_odds]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-456b37c853d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_smote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2130\u001b[0;31m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0m\u001b[1;32m   2131\u001b[0m                                               default_test_size=0.25)\n\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1810\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1811\u001b[0m             \u001b[0;34m'With n_samples={}, test_size={} and train_size={}, the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_smote = data_df.drop(columns=[\"won\"])\n",
    "\n",
    "y_smote = data_df[\"won\"]\n",
    "\n",
    "\n",
    "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_smote, y_smote, random_state=1, stratify = y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      1.00      1.00      1.00      1.00     10164\n",
      "          1       0.97      1.00      1.00      0.98      1.00      1.00       868\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1.00      1.00      1.00     11032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy=1.0).fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test_smote)\n",
    "balanced_accuracy_score(y_test_smote, y_pred)\n",
    "confusion_matrix(y_test_smote, y_pred)\n",
    "print(classification_report_imbalanced(y_test_smote, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_best.head(50)\n",
    "\n",
    "X_train_smote.to_csv(\"X_train_smote.csv\")\n",
    "y_train_smote.to_csv(\"y_train_smote.csv\")\n",
    "\n",
    "X_test_smote.to_csv(\"X_test_smote.csv\")\n",
    "y_test_smote.to_csv(\"y_test_smote.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training Data Score: {model.score(X_train_scaled_best, y_train_best)}\")\n",
    "# print(f\"Testing Data Score: {model.score(X_test_scaled_best, y_test_best)}\")\n",
    "# print(f\"for one single line:{model.predict(X_train_scaled_best[12].reshape(1,-1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.07186982e-06, -1.71315765e-05, -1.02404674e-03,\n",
       "        -5.26603009e-02, -1.44194656e-01, -2.72862448e-01,\n",
       "        -4.25629248e-01,  3.27668214e+00, -1.44194656e-01,\n",
       "        -4.17057104e-01, -8.42686352e-01,  2.43399579e+00,\n",
       "        -3.07767670e+01,  1.93379453e-02, -5.58264656e-02,\n",
       "        -8.46558807e-01,  1.21059263e+00, -8.76090813e-01,\n",
       "        -8.21911015e-01, -1.17268034e+00, -5.54683350e+00,\n",
       "        -1.14645333e-02,  4.18957671e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.2766821391032104, 'sec_time4'),\n",
       " (2.433995787070235, 'ldr_time4'),\n",
       " (1.210592627785416, 'behind_sec4'),\n",
       " (0.04189576710471376, 'place_odds'),\n",
       " (0.01933794528992767, 'behind_sec1'),\n",
       " (1.0718698194407978e-06, 'race_id'),\n",
       " (-1.713157645996128e-05, 'horse_id'),\n",
       " (-0.001024046737486871, 'distance'),\n",
       " (-0.011464533336377898, 'win_odds'),\n",
       " (-0.0526603009345888, 'race_class'),\n",
       " (-0.05582646560813039, 'behind_sec2'),\n",
       " (-0.1441946562200837, 'sec_time1'),\n",
       " (-0.1441946562200837, 'ldr_time1'),\n",
       " (-0.2728624481339311, 'sec_time2'),\n",
       " (-0.41705710430456594, 'ldr_time2'),\n",
       " (-0.4256292477312175, 'sec_time3'),\n",
       " (-0.8219110146459716, 'time2'),\n",
       " (-0.8426863520943787, 'ldr_time3'),\n",
       " (-0.8465588065971713, 'behind_sec3'),\n",
       " (-0.876090812636561, 'time1'),\n",
       " (-1.1726803389941436, 'time3'),\n",
       " (-5.5468334974224405, 'time4'),\n",
       " (-30.776766984984356, 'lengths_behind')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(model.coef_[0], np.asarray(X_smote.columns)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# while i < 5000:\n",
    "#     print(f\"{i}for one single line:{horse_model_best.predict(X_train_scaled_best[i].reshape(1,-1))}\")\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train_smote\n",
    "# X_train_best.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['horse_model_smote.sav']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'horse_model_smote.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('horse_model_smote.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = pd.DataFrame([[4871,1619,1800,3,14.05,21.86,24.17,24.31,14.05,35.91,60.08,84.39,0,1.75,4.25,3.5,1,14.33,22.26,24.05,23.91,4.9,1.0\n",
    "]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for one single line:[1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"for one single line:{model.predict(Xtest)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATABASE CONNECTION ONLY DO THESE ONCE EVEN IF RUNNING MODEL AGAIN...\n",
    "engine = create_engine('postgresql://postgres:'+sqlkey+'@localhost:5432/horse_races')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to push data being used for tableau\n",
    "#PUSH DATAFRAME TO POSTGRESQL ONLY PUSH ONCE\n",
    "data_df.to_sql(name='best_data_set', con=connection, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
